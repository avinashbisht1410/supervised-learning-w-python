{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeHA6/NI9o74OLALl7bURv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avinashbisht1410/supervised-learning-w-python/blob/master/Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case study 2: Petrol consumption using Random Forest\n",
        "\n",
        "For a random forest regression problem, we will be using the same case study we used for decision tree. In the interest of space, we are progressing after creating the training and testing dataset"
      ],
      "metadata": {
        "id": "9kk7Bay8l1S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import all the libraries and the dataset. We have already covered the steps while we were implementing decision tree algorithms."
      ],
      "metadata": {
        "id": "yBbsVuNhl-61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "petrol_data = pd.read_csv('petrol_consumption.csv')\n",
        "X = petrol_data.drop('Petrol_Consumption', axis=1)\n",
        "y = petrol_data['Petrol_Consumption']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "f-oa95e5mBNl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Import the random forest regressor library and initiate a RandomForestRegressor variable."
      ],
      "metadata": {
        "id": "gooA_8y6mKq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "randomForestModel = RandomForestRegressor(n_estimators=200,\n",
        "                               bootstrap = True,\n",
        "                               max_features = 'sqrt')"
      ],
      "metadata": {
        "id": "lyilVWBJmL2k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Now fit the model on training and testing data."
      ],
      "metadata": {
        "id": "jHr3GU-PmP-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randomForestModel.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "MOxzTYvBmSGb",
        "outputId": "254c45a0-37f6-440f-a5ce-ecdf9bf7d92f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_features='sqrt', n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: We will now predict the actual values and check the accuracy of the model."
      ],
      "metadata": {
        "id": "5XQqfVNYmU3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predictions = randomForestModel.predict(X_test)\n",
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, rf_predictions))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, rf_predictions))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, rf_predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNwC70kDmXl8",
        "outputId": "aadaf046-961b-4ac6-96f7-68c3a80261bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 47.731999999999985\n",
            "Mean Squared Error: 3449.5912699999994\n",
            "Root Mean Squared Error: 58.733221178477855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Now we will extract the two most important features. Get the list of all the columns present in the dataset and we will get the numeric feature importance."
      ],
      "metadata": {
        "id": "nuEXuvcpmfaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list=X_train.columns\n",
        "importances = list(randomForestModel.feature_importances_)\n",
        "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRWdmUGpmgwT",
        "outputId": "d20935b9-240d-4f8f-ca8f-b32e99069768"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: Population_Driver_licence(%) Importance: 0.45\n",
            "Variable: Average_income       Importance: 0.27\n",
            "Variable: Petrol_tax           Importance: 0.15\n",
            "Variable: Paved_Highways       Importance: 0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: We will now re-create the model with important variables."
      ],
      "metadata": {
        "id": "nic9NjLQmkTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_most_important = RandomForestRegressor(n_estimators= 500, random_state=5)\n",
        "important_indices = [feature_list[2], feature_list[1]]\n",
        "train_important = X_train.loc[:, ['Paved_Highways','Average_income','Population_Driver_licence(%)']]\n",
        "test_important = X_test.loc[:, ['Paved_Highways','Average_income','Population_Driver_licence(%)']]\n",
        "train_important = X_train.loc[:, ['Paved_Highways','Average_income','Population_Driver_licence(%)']]\n",
        "test_important = X_test.loc[:, ['Paved_Highways','Average_income','Population_Driver_licence(%)']]"
      ],
      "metadata": {
        "id": "_-UuXayQmlT1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Train the random forest algorithm."
      ],
      "metadata": {
        "id": "ESFaIU5WmoL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_most_important.fit(train_important, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "UYHgv5Dhmq3O",
        "outputId": "5529875a-cee3-4eb6-e540-b2118e08970c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(n_estimators=500, random_state=5)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=500, random_state=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=500, random_state=5)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Make predictions and determine the error."
      ],
      "metadata": {
        "id": "_pDIk9_5mthv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = rf_most_important.predict(test_important)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmFQRCowmvjX",
        "outputId": "a94f1d28-6320-42ea-843c-99a706d3b6e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([605.83 , 484.104, 623.094, 589.88 , 628.962, 607.238, 604.546,\n",
              "       572.176, 473.598, 510.536])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Print the mean absolute error, mean squared error, and root mean squared error."
      ],
      "metadata": {
        "id": "68b5tZzBmyFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tBijR0tm0gc",
        "outputId": "ef2fe4b4-5759-4c9d-ae00-edc6a34aa9a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 56.80640000000001\n",
            "Mean Squared Error: 4410.0591032\n",
            "Root Mean Squared Error: 66.40827586378072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can observe, after selecting the significant variables the error has reduced for random forest."
      ],
      "metadata": {
        "id": "JzAA5zcPm25N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble learning allows us to collate the power of multiple models and then make a prediction. These models individually are weak but together act as a strong model for prediction. And that is the beauty of ensemble learning. We will now discuss pros and cons of ensemble learning.\n",
        "\n",
        "Advantages of ensemble learning:\n",
        "1.\n",
        "An ensemble model can result in lower variance and low bias. They generally have a better understanding of the data.\n",
        "\n",
        "\n",
        "2.\n",
        "The accuracy of ensemble methods is generally higher than regular methods.\n",
        "\n",
        "\n",
        "3.\n",
        "Random forest model is used to tackle overfitting, which is generally a concern for decision trees. Boosting is used for bias reduction.\n",
        "\n",
        "\n",
        "4.\n",
        "And most importantly, ensemble methods are a collection of individual models. Hence, more complex understanding of the data is generated.\n",
        "\n",
        "\n",
        "Challenges with ensemble learning:\n",
        "1.\n",
        "Owing to the complexity of ensemble learning, it is difficult to comprehend. For example, while we can easily visualize a decision tree it is difficult to visualize a random forest model.\n",
        "\n",
        "\n",
        "2.\n",
        "Complexity of the models does not make them easy to train, test, deploy, and refresh, which is generally not the case with other models.\n",
        "\n",
        "\n",
        "3.\n",
        "Sometimes, ensemble models take a long time to converge and train. And that increases the training time."
      ],
      "metadata": {
        "id": "Y0Jmf3YgnM2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble methods can be divided into two broad categories: bagging and boosting.\n",
        "1.\n",
        "Bagging models or bootstrap aggregation improves the overall accuracy by the means of several weak models. The following are major attributes for a bagging model:\n",
        "a.\n",
        "Bagging uses sampling with replacement to generate multiple datasets.\n",
        "\n",
        "\n",
        "b.\n",
        "It builds multiple predictors simultaneously and independently of each other.\n",
        "\n",
        "\n",
        "c.\n",
        "To achieve the final decision an average/vote is done. It means if we are trying to build a regression model, the average or median of all the respective predictions will be taken while for the classification model a voting is done.\n",
        "\n",
        "\n",
        "d.\n",
        "Bagging is an effective solution to tackle variance and reduce overfitting.\n",
        "\n",
        "\n",
        "e.\n",
        "Random forest is one of the examples of a bagging method (as shown in Figure 2-22).\n",
        "\n",
        "\n",
        "\n",
        "2.\n",
        "Boosting : Similar to bagging, boosting also is an ensemble method. The following are the main points about boosting algorithm:\n",
        "a.\n",
        "In boosting, the learners are grown sequentially from the last one.\n",
        "\n",
        "\n",
        "b.\n",
        "Each subsequent learner improves from the last iteration and focuses more on the errors in the last iteration.\n",
        "\n",
        "\n",
        "c.\n",
        "During the process of voting, higher vote is awarded to learners which have performed better.\n",
        "\n",
        "\n",
        "d.\n",
        "Boosting is generally slower than bagging but mostly performs better.\n",
        "\n",
        "\n",
        "e.\n",
        "Gradient boosting, extreme gradient boosting, and AdaBoosting are a few example solutions.\n",
        "\n",
        "\n",
        "\n",
        "It is time for us to develop a solution using random forest. We will be exploring more on boosting in Chapter 4, where we study supervised classification algorithms."
      ],
      "metadata": {
        "id": "0XQXD0aKnPFk"
      }
    }
  ]
}